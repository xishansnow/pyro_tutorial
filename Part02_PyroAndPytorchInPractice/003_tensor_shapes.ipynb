{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pyro 中的张量形状\n",
    "\n",
    "本教程介绍了 Pyro 对张量维度的组织方法。在开始之前，你应该先熟悉一下[PyTorch 广播机制](http://pytorch.org/docs/master/notes/broadcasting.html)。 在本教程之后，你可能还想阅读一下[枚举类型](http://pyro.ai/examples/enumeration.html)。\n",
    "\n",
    "#### 要点：\n",
    "\n",
    "- 通过右对齐来广播张量：`torch.ones(3,4,5) + torch.ones(5)`\n",
    "- 分布的形状 `.sample().shape == batch_shape + event_shape`\n",
    "- 分布的对数概率的形状  `.log_prob (x).shape == batch_shape`（而不是 `event_shape`！）\n",
    "- 使用 `.expand()` 实现批量样本的抽取，或者通过 `plate` 自动抽取\n",
    "- 使用 `my_dist.to_event(1)` 将某个维度声明为从属维度（即依赖其他维度）\n",
    "- 使用 `withpyro.plate('name', size):` 将某个维度声明为条件独立的\n",
    "- 所有维度必须声明为从属维度或条件独立维度\n",
    "- 尝试支持在左侧进行批处理，这可以让 Pyro 自动并行化\n",
    "    - 使用负指数，如 `x.sum(-1)` 而不是 `x.sum(2)` \n",
    "    - 使用省略号，如 `pixel = image[..., i, j]` \n",
    "    -  如果 `i,j` 是枚举的，使用 [Vindex](http ://docs.pyro.ai/en/dev/ops.html#pyro.ops.indexing.Vindex) ，例如：`pixel = Vindex(image)[..., i, j] `\n",
    "- 当使用 `pyro.plate` 的自动二次采样功能时，确保数据子采样被激活了： \n",
    "    - 方法1：通过捕获索引 `withpyro.plate(...) as i: ...`  实现手动子采样；\n",
    "    - 方法2：通过 `batch =pyro.subsample(data, event_dim=...)` 实现自动子采样。\n",
    "- 在调试时，使用 [Trace.format_shapes()](http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes) 检查迹中的所有形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "from torch.distributions import constraints\n",
    "from pyro.distributions import Bernoulli, Categorical, MultivariateNormal, Normal\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "from pyro.infer import Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "import pyro.poutine as poutine\n",
    "from pyro.optim import Adam\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.7.0')\n",
    "\n",
    "# We'll ue this helper to check our models are correct.\n",
    "def test_model(model, guide, loss):\n",
    "    pyro.clear_param_store()\n",
    "    loss.loss(model, guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 分布的形状： `batch_shape` 和 `event_shape`\n",
    "\n",
    "熟悉 PyTorch 的人都知道，其 `Tensor` ​​有一个 `.shape` 属性，但是 `Distribution` 有所不同，它有两个具有特殊含义的形状属性：`.batch_shape` 和 `.event_shape`。这两个属性结合起来定义了一个样本的总形状。\n",
    "\n",
    "```py\n",
    "x = d.sample()\n",
    "assert x.shape == d.batch_shape + d.event_shape\n",
    "```\n",
    "\n",
    "`.batch_shape` 上的索引表示条件独立型的随机变量，而`.event_shape` 上的索引则表示从属型的随机变量（即从某个分布中抽取出来的）。由于从属型的随机变量在一起定义概率， `.log_prob()` 方法只为形状 `.event_shape` 中的每个事件生成一个数值。因此`.log_prob()`的总形状是： `batch_shape`：\n",
    "\n",
    "```py\n",
    "assert d.log_prob(x).shape == d.batch_shape\n",
    "```\n",
    "\n",
    "注意 `Distribution.sample()` 方法也可以使用 `sample_shape` 参数来索引独立同分布（ I.I.D）的随机变量：\n",
    "\n",
    "```py\n",
    "x2 = d.sample(sample_shape)\n",
    "assert x2.shape == sample_shape + batch_shape + event_shape\n",
    "```\n",
    "\n",
    "总的来说，有如下关系：\n",
    "\n",
    "\n",
    "```\n",
    "      |      iid     | independent | dependent\n",
    "------+--------------+-------------+------------\n",
    "shape = sample_shape + batch_shape + event_shape\n",
    "```\n",
    "\n",
    "例如，单变量分布具有`空`的事件形状（因为每个数字都是一个独立事件）。像 `MultivariateNormal` 这样向量上的分布，则有 `len(event_shape) == 1`。 而像 `InverseWishart` 这样矩阵上的分布则具有 `len(event_shape) == 2` 。\n",
    "\n",
    "### 1.1 示例\n",
    "\n",
    "最简单的分布形状是一元随机变量的分布："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5)\n",
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == ()\n",
    "assert d.log_prob(x).shape == ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分布可以通过传递批参数，实现批处理，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5 * torch.ones(3,4))\n",
    "assert d.batch_shape == (3, 4)\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一种批方法是调用 `.expand()` 方法，这只有在参数沿最左侧维度相同时才有效。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Bernoulli(torch.tensor([0.1, 0.2, 0.3, 0.4])).expand([3, 4])\n",
    "assert d.batch_shape == (3, 4)\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多元随机变量的分布具有非空的 `.event_shape` 。对于这些分布而言， `.sample()` 和 `.log_prob(x)` 的形状是不同的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = MultivariateNormal(torch.zeros(3), torch.eye(3, 3))\n",
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == (3,)\n",
    "x = d.sample()\n",
    "assert x.shape == (3,)            # == batch_shape + event_shape\n",
    "assert d.log_prob(x).shape == ()  # == batch_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 分布的重新塑形 --- 整形\n",
    "\n",
    "在 Pyro 中，您可以通过调用 [.to_event(n)](http://docs.pyro.ai/en/dev/distributions.html#pyro.distributions.torch_distribution.TorchDistributionMixin.to_event) 属性将单变量分布视为多元分布处理，其中 `n` 是被声明为 **从属的** 的批维度数（从右侧开始）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5 * torch.ones(3,4)).to_event(1)\n",
    "assert d.batch_shape == (3,)\n",
    "assert d.event_shape == (4,)\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当您使用 Pyro 程序时，请记住，样本具有 `batch_shape + event_shape` 的形状，而 `.log_prob(x)` 具有 `batch_shape` 的形状。同时，您需要确保能够仔细地控制 `batch_shape`，通过使用 `.to_event(n)` 修剪的方式或通过 `pyro.plate` 将维度声明为独立的方式。\n",
    "\n",
    "### 1.3 做出依赖假设总是安全的\n",
    "\n",
    "通常在 Pyro 中，即使某些维度实际上是独立的，我们也会将其声明为具有依赖性的从属维度，例如：\n",
    "\n",
    "```py\n",
    "x = pyro.sample(\"x\", Normal(0, 1).expand([10]).to_event(1))\n",
    "assert x.shape == (10,)\n",
    "```\n",
    "这很有用，原因有两个：\n",
    "\n",
    "（1）它允许我们在 `MultivariateNormal` 分布中轻松地进行交换。\n",
    "（2）它稍微简化了代码，例如在下面的场景中，我们其实可以不使用 `plate`：\n",
    "\n",
    "```py\n",
    "with pyro.plate(\"x_plate\", 10):\n",
    "    x = pyro.sample(\"x\", Normal(0, 1))  # .expand([10]) is automatic\n",
    "    assert x.shape == (10,)\n",
    "```\n",
    "这两个版本之间的区别在于：带有 `plate` 的版本通知 Pyro ，它可以在估计梯度时利用条件独立信息；而在第一个版本中， Pyro 必须假设它们是有依赖的（即使实际上是条件独立的）。\n",
    "\n",
    "这类似于概率图模型中的 `d-separation`：添加边并假设变量可能相关（即扩大了模型类）总是安全的，但当变量实际上相关但被假设为独立时，通常是不安全的（即缩小了模型类，导致真正的模型可能位于模型类之外，就像在平均场一样）。在实践中，Pyro 的 SVI 推理算法使用面向 `正态` 分布的重参数化梯度估计器，因此两者的梯度估计具有相同的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 用 `plate` 来声明独立的维度\n",
    "\n",
    "Pyro 模型可以使用上下文管理器 [pyro.plate](http://docs.pyro.ai/en/dev/primitives.html#pyro.plate) 来声明某些维度是独立的。然后推断算法可以利用这种独立性来例如构造低方差的梯度估计器，或者在线性空间而不是指数空间中做枚举。独立维度的一个例子是小批量数据上的索引：每个数据点都应该独立于所有其他数据点。\n",
    "\n",
    "将维度声明为独立的最简单方法是：将最右侧的那些维度声明为独立的。\n",
    "\n",
    "\n",
    "```py\n",
    "with pyro.plate(\"my_plate\"):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "```\n",
    "\n",
    "我们推荐在调试过程中，一直提供 `size` 参数来辅助对形状的调试。\n",
    "\n",
    "```py\n",
    "with pyro.plate(\"my_plate\", len(my_data)):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "```\n",
    "\n",
    "从 Pyro 0.2 开始，可以实现嵌套的 `plate` ， 例如， 如果每个像素都具有独立性：\n",
    "\n",
    "```py\n",
    "with pyro.plate(\"x_axis\", 320):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "    with pyro.plate(\"y_axis\", 200):\n",
    "        # within this context, batch dimensions -2 and -1 are independent\n",
    "```\n",
    "\n",
    "请注意，我们总是使用负指数（如 -2、-1）从右侧开始计数。\n",
    "\n",
    "最后，如果你想混合和匹配多个 `plate` 时，例如，仅依赖于 `x` 的噪声、仅依赖于 `y` 的噪声、同时依赖于两者的噪声等，可以声明多个 `plate` ​​并将它们用作可重用的上下文管理器。此时， Pyro 无法自动分配维度，因此需要你提供一个 `dim` 参数（依然是右侧计数）：\n",
    "\n",
    "```py\n",
    "x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "with x_axis:\n",
    "    # within this context, batch dimension -2 is independent\n",
    "with y_axis:\n",
    "    # within this context, batch dimension -3 is independent\n",
    "with x_axis, y_axis:\n",
    "    # within this context, batch dimensions -3 and -2 are independent\n",
    "```\n",
    "\n",
    "让我们仔细看看`plate`内的批大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    a = pyro.sample(\"a\", Normal(0, 1))\n",
    "    b = pyro.sample(\"b\", Normal(torch.zeros(2), 1).to_event(1))\n",
    "    with pyro.plate(\"c_plate\", 2):\n",
    "        c = pyro.sample(\"c\", Normal(torch.zeros(2), 1))\n",
    "    with pyro.plate(\"d_plate\", 3):\n",
    "        d = pyro.sample(\"d\", Normal(torch.zeros(3,4,5), 1).to_event(2))\n",
    "    assert a.shape == ()       # batch_shape == ()     event_shape == ()\n",
    "    assert b.shape == (2,)     # batch_shape == ()     event_shape == (2,)\n",
    "    assert c.shape == (2,)     # batch_shape == (2,)   event_shape == ()\n",
    "    assert d.shape == (3,4,5)  # batch_shape == (3,)   event_shape == (4,5) \n",
    "\n",
    "    x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "    y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "    with x_axis:\n",
    "        x = pyro.sample(\"x\", Normal(0, 1))\n",
    "    with y_axis:\n",
    "        y = pyro.sample(\"y\", Normal(0, 1))\n",
    "    with x_axis, y_axis:\n",
    "        xy = pyro.sample(\"xy\", Normal(0, 1))\n",
    "        z = pyro.sample(\"z\", Normal(0, 1).expand([5]).to_event(1))\n",
    "    assert x.shape == (3, 1)        # batch_shape == (3,1)     event_shape == ()\n",
    "    assert y.shape == (2, 1, 1)     # batch_shape == (2,1,1)   event_shape == ()\n",
    "    assert xy.shape == (2, 3, 1)    # batch_shape == (2,3,1)   event_shape == ()\n",
    "    assert z.shape == (2, 3, 1, 5)  # batch_shape == (2,3,1)   event_shape == (5,)\n",
    "    \n",
    "test_model(model1, model1, Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过在 `batch_shape` 和 `event_shape` 之间的边界处做对齐，来可视化每个样本点的 `.shape`，对于形状调试非常有帮助：边界右侧的维度将在 `.log_prob()` 中汇集，而左侧的维度将会留存。\n",
    "\n",
    "```\n",
    "batch dims | event dims\n",
    "-----------+-----------\n",
    "           |        a = sample(\"a\", Normal(0, 1))\n",
    "           |2       b = sample(\"b\", Normal(zeros(2), 1)\n",
    "           |                        .to_event(1))\n",
    "           |        with plate(\"c\", 2):\n",
    "          2|            c = sample(\"c\", Normal(zeros(2), 1))\n",
    "           |        with plate(\"d\", 3):\n",
    "          3|4 5         d = sample(\"d\", Normal(zeros(3,4,5), 1)\n",
    "           |                       .to_event(2))\n",
    "           |\n",
    "           |        x_axis = plate(\"x\", 3, dim=-2)\n",
    "           |        y_axis = plate(\"y\", 2, dim=-3)\n",
    "           |        with x_axis:\n",
    "        3 1|            x = sample(\"x\", Normal(0, 1))\n",
    "           |        with y_axis:\n",
    "      2 1 1|            y = sample(\"y\", Normal(0, 1))\n",
    "           |        with x_axis, y_axis:\n",
    "      2 3 1|            xy = sample(\"xy\", Normal(0, 1))\n",
    "      2 3 1|5           z = sample(\"z\", Normal(0, 1).expand([5])\n",
    "           |                       .to_event(1))\n",
    "```\n",
    "\n",
    "要实现程序中样本点形状的自动检查，你可以跟踪程序并使用 [Trace.format_shapes()](http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes) 方法，它会为每个样本点打印三个形状：分布的形状（`site[\"fn\"].batch_shape + site[\"fn\"].event_shape`）、值形状（`site[ \"value\"].shape`) 和对数概率形状（`site[\"log_prob\"].shape`）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Shapes:            \n",
      " Param Sites:            \n",
      "Sample Sites:            \n",
      "       a dist       |    \n",
      "        value       |    \n",
      "     log_prob       |    \n",
      "       b dist       | 2  \n",
      "        value       | 2  \n",
      "     log_prob       |    \n",
      " c_plate dist       |    \n",
      "        value     2 |    \n",
      "     log_prob       |    \n",
      "       c dist     2 |    \n",
      "        value     2 |    \n",
      "     log_prob     2 |    \n",
      " d_plate dist       |    \n",
      "        value     3 |    \n",
      "     log_prob       |    \n",
      "       d dist     3 | 4 5\n",
      "        value     3 | 4 5\n",
      "     log_prob     3 |    \n",
      "  x_axis dist       |    \n",
      "        value     3 |    \n",
      "     log_prob       |    \n",
      "  y_axis dist       |    \n",
      "        value     2 |    \n",
      "     log_prob       |    \n",
      "       x dist   3 1 |    \n",
      "        value   3 1 |    \n",
      "     log_prob   3 1 |    \n",
      "       y dist 2 1 1 |    \n",
      "        value 2 1 1 |    \n",
      "     log_prob 2 1 1 |    \n",
      "      xy dist 2 3 1 |    \n",
      "        value 2 3 1 |    \n",
      "     log_prob 2 3 1 |    \n",
      "       z dist 2 3 1 | 5  \n",
      "        value 2 3 1 | 5  \n",
      "     log_prob 2 3 1 |    \n"
     ]
    }
   ],
   "source": [
    "trace = poutine.trace(model1).get_trace()\n",
    "trace.compute_log_prob()  # optional, but allows printing of log_prob shapes\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 `plate` 内部的二次采样张量\n",
    "\n",
    "[plate](http://docs.pyro.ai/en/dev/primitives.html#pyro.plate) 的主要用途之一是对数据进行二次采样。这在 `plate` 中是可能的：由于数据具备（条件）独立性，因此一半数据的损失期望值，在理论上，应当是完整数据损失期望值的一半。\n",
    "\n",
    "为了做数据的二次采样，你需要通知 Pyro 全数据集和二次采样数据集的大小，Pyro 会自动选择一个随机子集，并生成索引集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.arange(100.)\n",
    "\n",
    "def model2():\n",
    "    mean = pyro.param(\"mean\", torch.zeros(len(data)))\n",
    "    with pyro.plate(\"data\", len(data), subsample_size=10) as ind:\n",
    "        assert len(ind) == 10    # ind is a LongTensor that indexes the subsample.\n",
    "        batch = data[ind]        # Select a minibatch of data.\n",
    "        mean_batch = mean[ind]   # Take care to select the relevant per-datum parameters.\n",
    "        # Do stuff with batch:\n",
    "        x = pyro.sample(\"x\", Normal(mean_batch, 1), obs=batch)\n",
    "        assert len(x) == 10\n",
    "        \n",
    "test_model(model2, guide=lambda: None, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 允许并行枚举的广播机制\n",
    "\n",
    "Pyro 0.2 引入了并行地枚举离散隐变量的功能。当通过 [SVI](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.svi.SVI) 学习后验时，这可以显着减少梯度估计器的方差。\n",
    "\n",
    "要使用并行枚举，Pyro 需要分配可用于枚举的张量维。为了避免与用于 `plate` 的其他维度发生冲突，需要预计并声明即将使用的最大张量维数。这个预计值被称为 `max_plate_nesting` 并且是 [SVI](http://docs.pyro.ai/en/dev/inference_algos.html)的一个参数，该参数被简单地传递给[TraceEnum_ELBO](http:// docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.traceenum_elbo.TraceEnum_ELBO)。通常 Pyro 可以自己确定这个预计值（通过运行一次 `model` 和 `guide` 对并记录运行情况），但在动态模型结构情况下，可能需要手动声明 `max_plate_nesting`。\n",
    "\n",
    "要了解 `max_plate_nesting` 以及 Pyro 如何为枚举分配维度，让我们从上面重新审视 `model1()`。这次我们将绘制三种类型的维度：左侧的 `enumeration dimensions` （Pyro 控制这些维度）、中间的 `batch dimensions` 和右侧的 `event dimensions` 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "      max_plate_nesting = 3\n",
    "           |<--->|\n",
    "enumeration|batch|event\n",
    "-----------+-----+-----\n",
    "           |. . .|      a = sample(\"a\", Normal(0, 1))\n",
    "           |. . .|2     b = sample(\"b\", Normal(zeros(2), 1)\n",
    "           |     |                      .to_event(1))\n",
    "           |     |      with plate(\"c\", 2):\n",
    "           |. . 2|          c = sample(\"c\", Normal(zeros(2), 1))\n",
    "           |     |      with plate(\"d\", 3):\n",
    "           |. . 3|4 5       d = sample(\"d\", Normal(zeros(3,4,5), 1)\n",
    "           |     |                     .to_event(2))\n",
    "           |     |\n",
    "           |     |      x_axis = plate(\"x\", 3, dim=-2)\n",
    "           |     |      y_axis = plate(\"y\", 2, dim=-3)\n",
    "           |     |      with x_axis:\n",
    "           |. 3 1|          x = sample(\"x\", Normal(0, 1))\n",
    "           |     |      with y_axis:\n",
    "           |2 1 1|          y = sample(\"y\", Normal(0, 1))\n",
    "           |     |      with x_axis, y_axis:\n",
    "           |2 3 1|          xy = sample(\"xy\", Normal(0, 1))\n",
    "           |2 3 1|5         z = sample(\"z\", Normal(0, 1).expand([5]))\n",
    "           |     |                     .to_event(1))\n",
    "```\n",
    "\n",
    "请注意，过度配置 `max_plate_nesting=4` 总是安全的，但不能配置不足，例如  `max_plate_nesting=2` 时， Pyro 会出错。\n",
    "\n",
    "让我们看看这在实践中是如何工作的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config_enumerate\n",
    "def model3():\n",
    "    p = pyro.param(\"p\", torch.arange(6.) / 6)\n",
    "    locs = pyro.param(\"locs\", torch.tensor([-1., 1.]))\n",
    "\n",
    "    a = pyro.sample(\"a\", Categorical(torch.ones(6) / 6))\n",
    "    b = pyro.sample(\"b\", Bernoulli(p[a]))  # Note this depends on a.\n",
    "    with pyro.plate(\"c_plate\", 4):\n",
    "        c = pyro.sample(\"c\", Bernoulli(0.3))\n",
    "        with pyro.plate(\"d_plate\", 5):\n",
    "            d = pyro.sample(\"d\", Bernoulli(0.4))\n",
    "            e_loc = locs[d.long()].unsqueeze(-1)\n",
    "            e_scale = torch.arange(1., 8.)\n",
    "            e = pyro.sample(\"e\", Normal(e_loc, e_scale)\n",
    "                            .to_event(1))  # Note this depends on d.\n",
    "\n",
    "    #                   enumerated|batch|event dims\n",
    "    assert a.shape == (         6, 1, 1   )  # Six enumerated values of the Categorical.\n",
    "    assert b.shape == (      2, 1, 1, 1   )  # Two enumerated Bernoullis, unexpanded.\n",
    "    assert c.shape == (   2, 1, 1, 1, 1   )  # Only two Bernoullis, unexpanded.\n",
    "    assert d.shape == (2, 1, 1, 1, 1, 1   )  # Only two Bernoullis, unexpanded.\n",
    "    assert e.shape == (2, 1, 1, 1, 5, 4, 7)  # This is sampled and depends on d.\n",
    "\n",
    "    assert e_loc.shape   == (2, 1, 1, 1, 1, 1, 1,)\n",
    "    assert e_scale.shape == (                  7,)\n",
    "            \n",
    "test_model(model3, model3, TraceEnum_ELBO(max_plate_nesting=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们仔细看看这些维度。首先注意，Pyro 从 `max_plate_nesting` 的右侧开始分配枚举维度：Pyro 分配维度 -3 来枚举 `a`，然后维度 -4 来枚举 `b`，然后维度 -5 来枚举 `c`，最后是维度 -6 来枚举 `d`。 接下来请注意，样本在新的枚举维度中只有范围（size > 1）。这有助于保持张量小型化且降低计算成本。 请注意，`log_prob` 形状将被广播以包含 `enumeration dimensions` 和  `batch dimensions` 形状，因此 `trace.nodes['d']['log_prob'].shape == (2, 1, 1, 1, 5, 4)` 。\n",
    "\n",
    "我们可以绘制相似的张量维度图：\n",
    "\n",
    "```\n",
    "     max_plate_nesting = 2\n",
    "            |<->|\n",
    "enumeration batch event\n",
    "------------|---|-----\n",
    "           6|1 1|     a = pyro.sample(\"a\", Categorical(torch.ones(6) / 6))\n",
    "         2 1|1 1|     b = pyro.sample(\"b\", Bernoulli(p[a]))\n",
    "            |   |     with pyro.plate(\"c_plate\", 4):\n",
    "       2 1 1|1 1|         c = pyro.sample(\"c\", Bernoulli(0.3))\n",
    "            |   |         with pyro.plate(\"d_plate\", 5):\n",
    "     2 1 1 1|1 1|             d = pyro.sample(\"d\", Bernoulli(0.4))\n",
    "     2 1 1 1|1 1|1            e_loc = locs[d.long()].unsqueeze(-1)\n",
    "            |   |7            e_scale = torch.arange(1., 8.)\n",
    "     2 1 1 1|5 4|7            e = pyro.sample(\"e\", Normal(e_loc, e_scale)\n",
    "            |   |                             .to_event(1))\n",
    "```\n",
    "为了使用枚举语义自动检查这个模型，可以创建一个枚举 `Trace`，然后使用 [Trace.format_shapes()](http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.shpaes) ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Shapes:                \n",
      " Param Sites:                \n",
      "            p             6  \n",
      "         locs             2  \n",
      "Sample Sites:                \n",
      "       a dist             |  \n",
      "        value       6 1 1 |  \n",
      "     log_prob       6 1 1 |  \n",
      "       b dist       6 1 1 |  \n",
      "        value     2 1 1 1 |  \n",
      "     log_prob     2 6 1 1 |  \n",
      " c_plate dist             |  \n",
      "        value           4 |  \n",
      "     log_prob             |  \n",
      "       c dist           4 |  \n",
      "        value   2 1 1 1 1 |  \n",
      "     log_prob   2 1 1 1 4 |  \n",
      " d_plate dist             |  \n",
      "        value           5 |  \n",
      "     log_prob             |  \n",
      "       d dist         5 4 |  \n",
      "        value 2 1 1 1 1 1 |  \n",
      "     log_prob 2 1 1 1 5 4 |  \n",
      "       e dist 2 1 1 1 5 4 | 7\n",
      "        value 2 1 1 1 5 4 | 7\n",
      "     log_prob 2 1 1 1 5 4 |  \n"
     ]
    }
   ],
   "source": [
    "trace = poutine.trace(poutine.enum(model3, first_available_dim=-3)).get_trace()\n",
    "trace.compute_log_prob()  # optional, but allows printing of log_prob shapes\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 编写可并行的代码\n",
    "\n",
    "编写能够正确并行化处理样本点的 Pyro 模型可能很棘手。两个技巧可能会有帮助：\n",
    "\n",
    "一是[广播机制](http://pytorch.org/docs/master/notes/broadcasting.html) ；\n",
    "\n",
    "二是[ellipsis 切片](http://python-reference.readthedocs.io/en/dev/docs/brackets/ellipsis.html) 。\n",
    "\n",
    "让我们通过以下模型来看看在实践中它们是如何工作的。我们的目标是编写一个既可以使用枚举也可以不使用枚举的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 8\n",
    "height = 10\n",
    "sparse_pixels = torch.LongTensor([[3, 2], [3, 5], [3, 9], [7, 1]])\n",
    "enumerated = None  # set to either True or False below\n",
    "\n",
    "def fun(observe):\n",
    "    p_x = pyro.param(\"p_x\", torch.tensor(0.1), constraint=constraints.unit_interval)\n",
    "    p_y = pyro.param(\"p_y\", torch.tensor(0.1), constraint=constraints.unit_interval)\n",
    "    x_axis = pyro.plate('x_axis', width, dim=-2)\n",
    "    y_axis = pyro.plate('y_axis', height, dim=-1)\n",
    "\n",
    "    # Note that the shapes of these sites depend on whether Pyro is enumerating.\n",
    "    with x_axis:\n",
    "        x_active = pyro.sample(\"x_active\", Bernoulli(p_x))\n",
    "    with y_axis:\n",
    "        y_active = pyro.sample(\"y_active\", Bernoulli(p_y))\n",
    "    if enumerated:\n",
    "        assert x_active.shape  == (2, 1, 1)\n",
    "        assert y_active.shape  == (2, 1, 1, 1)\n",
    "    else:\n",
    "        assert x_active.shape  == (width, 1)\n",
    "        assert y_active.shape  == (height,)\n",
    "\n",
    "    # The first trick is to broadcast. This works with or without enumeration.\n",
    "    p = 0.1 + 0.5 * x_active * y_active\n",
    "    if enumerated:\n",
    "        assert p.shape == (2, 2, 1, 1)\n",
    "    else:\n",
    "        assert p.shape == (width, height)\n",
    "    dense_pixels = p.new_zeros(broadcast_shape(p.shape, (width, height)))\n",
    "\n",
    "    # The second trick is to index using ellipsis slicing.\n",
    "    # This allows Pyro to add arbitrary dimensions on the left.\n",
    "    for x, y in sparse_pixels:\n",
    "        dense_pixels[..., x, y] = 1\n",
    "    if enumerated:\n",
    "        assert dense_pixels.shape == (2, 2, width, height)\n",
    "    else:\n",
    "        assert dense_pixels.shape == (width, height)\n",
    "\n",
    "    with x_axis, y_axis:    \n",
    "        if observe:\n",
    "            pyro.sample(\"pixels\", Bernoulli(p), obs=dense_pixels)\n",
    "\n",
    "def model4():\n",
    "    fun(observe=True)\n",
    "\n",
    "def guide4():\n",
    "    fun(observe=False)\n",
    "\n",
    "# Test without enumeration.\n",
    "enumerated = False\n",
    "test_model(model4, guide4, Trace_ELBO())\n",
    "\n",
    "# Test with enumeration.\n",
    "enumerated = True\n",
    "test_model(model4, config_enumerate(guide4, \"parallel\"),\n",
    "           TraceEnum_ELBO(max_plate_nesting=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 在 `pyro.plate` 内部的自动广播\n",
    "\n",
    "请注意，在所有的`模型/引导` 定义中，我们都依赖 [pyro.plate](http://docs.pyro.ai/en/dev/primitives.html#pyro.plate) 自动扩展样本形状以满足由 `pyro.sample` 语句强制执行的批形状约束。不过，这种广播机制等效于手动说明的 `.expand()` 语句。\n",
    "\n",
    "我们将使用 [上一节](#Writing-parallelizable-code) 中的 `model4` 来演示这一点。需要对之前代码的以下更改： \n",
    "\n",
    "- 出于本示例的目的，将仅考虑 `并行` 枚举，但广播应该在没有枚举或使用 `顺序` 枚举的情况下按预期工作。 \n",
    "\n",
    "- 我们已经分离出采样函数，该函数返回与活动像素对应的张量。将模型代码模块化为组件是一种常见做法，有助于大型模型的可维护性。 \n",
    "\n",
    "- 我们还想使用 `pyro.plate` 能够构造在 [num_particles](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.elbo.ELBO) 上并行化的 ELBO 估计器。这是通过将 `模型/引导` 的内容包装在最外层 `pyro.plate` 的上下文中来完成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 100  # Number of samples for the ELBO estimator\n",
    "width = 8\n",
    "height = 10\n",
    "sparse_pixels = torch.LongTensor([[3, 2], [3, 5], [3, 9], [7, 1]])\n",
    "\n",
    "def sample_pixel_locations_no_broadcasting(p_x, p_y, x_axis, y_axis):\n",
    "    with x_axis:\n",
    "        x_active = pyro.sample(\"x_active\", Bernoulli(p_x).expand([num_particles, width, 1]))\n",
    "    with y_axis:\n",
    "        y_active = pyro.sample(\"y_active\", Bernoulli(p_y).expand([num_particles, 1, height]))\n",
    "    return x_active, y_active\n",
    "\n",
    "def sample_pixel_locations_full_broadcasting(p_x, p_y, x_axis, y_axis):\n",
    "    with x_axis:\n",
    "        x_active = pyro.sample(\"x_active\", Bernoulli(p_x))\n",
    "    with y_axis:\n",
    "        y_active = pyro.sample(\"y_active\", Bernoulli(p_y))\n",
    "    return x_active, y_active \n",
    "\n",
    "def sample_pixel_locations_partial_broadcasting(p_x, p_y, x_axis, y_axis):\n",
    "    with x_axis:\n",
    "        x_active = pyro.sample(\"x_active\", Bernoulli(p_x).expand([width, 1]))\n",
    "    with y_axis:\n",
    "        y_active = pyro.sample(\"y_active\", Bernoulli(p_y).expand([height]))\n",
    "    return x_active, y_active \n",
    "\n",
    "def fun(observe, sample_fn):\n",
    "    p_x = pyro.param(\"p_x\", torch.tensor(0.1), constraint=constraints.unit_interval)\n",
    "    p_y = pyro.param(\"p_y\", torch.tensor(0.1), constraint=constraints.unit_interval)\n",
    "    x_axis = pyro.plate('x_axis', width, dim=-2)\n",
    "    y_axis = pyro.plate('y_axis', height, dim=-1)\n",
    "\n",
    "    with pyro.plate(\"num_particles\", 100, dim=-3):\n",
    "        x_active, y_active = sample_fn(p_x, p_y, x_axis, y_axis)\n",
    "        # Indices corresponding to \"parallel\" enumeration are appended \n",
    "        # to the left of the \"num_particles\" plate dim.\n",
    "        assert x_active.shape  == (2, 1, 1, 1)\n",
    "        assert y_active.shape  == (2, 1, 1, 1, 1)\n",
    "        p = 0.1 + 0.5 * x_active * y_active\n",
    "        assert p.shape == (2, 2, 1, 1, 1)\n",
    "\n",
    "        dense_pixels = p.new_zeros(broadcast_shape(p.shape, (width, height)))\n",
    "        for x, y in sparse_pixels:\n",
    "            dense_pixels[..., x, y] = 1\n",
    "        assert dense_pixels.shape == (2, 2, 1, width, height)\n",
    "\n",
    "        with x_axis, y_axis:    \n",
    "            if observe:\n",
    "                pyro.sample(\"pixels\", Bernoulli(p), obs=dense_pixels)\n",
    "\n",
    "def test_model_with_sample_fn(sample_fn):\n",
    "    def model():\n",
    "        fun(observe=True, sample_fn=sample_fn)\n",
    "\n",
    "    @config_enumerate\n",
    "    def guide():\n",
    "        fun(observe=False, sample_fn=sample_fn)\n",
    "\n",
    "    test_model(model, guide, TraceEnum_ELBO(max_plate_nesting=3))\n",
    "\n",
    "test_model_with_sample_fn(sample_pixel_locations_no_broadcasting)\n",
    "test_model_with_sample_fn(sample_pixel_locations_full_broadcasting)\n",
    "test_model_with_sample_fn(sample_pixel_locations_partial_broadcasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第一个采样函数中，我们必须进行一些手动记录并扩展 `伯努利` 分布的批形状，以应对由 `pyro.plate` 上下文添加的条件独立性维度。特别要注意， `sample_pixel_locations` 需要有关`num_particles`、`width` 和`height` 的知识，并且会从全局范围访问这些变量，这并不理想。\n",
    "\n",
    "- 需要提供 `pyro.plate` 的第二个参数，即可选的 `size` 参数，用于隐式广播，以便可以推断每个样本点的批形状要求。 \n",
    "\n",
    "- 样本点的现有 `batch_shape` 必须能够以 `pyro.plate` 上下文中的大小进行广播。在此处的特定示例中，`Bernoulli(p_x)` 有一个空的批形状，它是普遍可广播的。\n",
    "\n",
    "请注意使用 `pyro.plate` 并通过张量化操作实现并行化是多么简单！ `pyro.plate` 还有助于代码模块化，因为模型组件可以编写为与 `plate` 上下文无关，它们随后可能会嵌入其中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
